{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Product Brainstorming\n",
    "\n",
    "Can we use TinyTroupe to brainstorm product ideas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "!!!!\n",
      "DISCLAIMER: TinyTroupe relies on Artificial Intelligence (AI) models to generate content. \n",
      "The AI models are not perfect and may produce inappropriate or inacurate results. \n",
      "For any serious or consequential use, please review the generated content before using it.\n",
      "!!!!\n",
      "\n",
      "Looking for default config on: s:\\TinyTroupeOllama\\examples\\..\\tinytroupe\\config.ini\n",
      "Found custom config on: s:\\TinyTroupeOllama\\examples\\config.ini\n",
      "\n",
      "=================================\n",
      "Current TinyTroupe configuration \n",
      "=================================\n",
      "[OpenAI]\n",
      "api_type = openai\n",
      "azure_api_version = 2023-05-15\n",
      "model = llama3.2\n",
      "max_tokens = 4000\n",
      "temperature = 1.5\n",
      "freq_penalty = 0.3\n",
      "presence_penalty = 0.0\n",
      "timeout = 60\n",
      "max_attempts = 5\n",
      "waiting_time = 2\n",
      "exponential_backoff_factor = 5\n",
      "embedding_model = mxbai-embed-large:latest\n",
      "cache_api_calls = False\n",
      "cache_file_name = openai_api_cache.pickle\n",
      "max_content_display_length = 1024\n",
      "openai_api_base = http://localhost:11434\n",
      "base_url = http://localhost:11434\n",
      "\n",
      "[Simulation]\n",
      "rai_harmful_content_prevention = True\n",
      "rai_copyright_infringement_prevention = True\n",
      "\n",
      "[Logging]\n",
      "loglevel = ERROR\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'mxbai-embed-large:latest' is not a valid OpenAIEmbeddingModelType",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtinytroupe\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtinytroupe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magent\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TinyPerson\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtinytroupe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menvironment\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TinyWorld, TinySocialNetwork\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtinytroupe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexamples\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32ms:\\TinyTroupeOllama\\examples\\..\\tinytroupe\\agent.py:72\u001b[0m\n\u001b[0;32m     70\u001b[0m     llmaindex_openai_embed_model \u001b[38;5;241m=\u001b[39m OpenAIEmbedding(model\u001b[38;5;241m=\u001b[39mcustom_model_name, embed_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 72\u001b[0m     llmaindex_openai_embed_model \u001b[38;5;241m=\u001b[39m \u001b[43mOpenAIEmbedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_model_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madditional_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_model_name\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m Settings\u001b[38;5;241m.\u001b[39membed_model \u001b[38;5;241m=\u001b[39m llmaindex_openai_embed_model\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m###############################################################################\u001b[39;00m\n",
      "File \u001b[1;32ms:\\TinyTroupeOllama\\.venv\\Lib\\site-packages\\llama_index\\embeddings\\openai\\base.py:301\u001b[0m, in \u001b[0;36mOpenAIEmbedding.__init__\u001b[1;34m(self, mode, model, embed_batch_size, dimensions, additional_kwargs, api_key, api_base, api_version, max_retries, timeout, reuse_client, callback_manager, default_headers, http_client, async_http_client, num_workers, **kwargs)\u001b[0m\n\u001b[0;32m    293\u001b[0m     additional_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdimensions\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m dimensions\n\u001b[0;32m    295\u001b[0m api_key, api_base, api_version \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resolve_credentials(\n\u001b[0;32m    296\u001b[0m     api_key\u001b[38;5;241m=\u001b[39mapi_key,\n\u001b[0;32m    297\u001b[0m     api_base\u001b[38;5;241m=\u001b[39mapi_base,\n\u001b[0;32m    298\u001b[0m     api_version\u001b[38;5;241m=\u001b[39mapi_version,\n\u001b[0;32m    299\u001b[0m )\n\u001b[1;32m--> 301\u001b[0m query_engine \u001b[38;5;241m=\u001b[39m \u001b[43mget_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_QUERY_MODE_MODEL_DICT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    302\u001b[0m text_engine \u001b[38;5;241m=\u001b[39m get_engine(mode, model, _TEXT_MODE_MODEL_DICT)\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n",
      "File \u001b[1;32ms:\\TinyTroupeOllama\\.venv\\Lib\\site-packages\\llama_index\\embeddings\\openai\\base.py:204\u001b[0m, in \u001b[0;36mget_engine\u001b[1;34m(mode, model, mode_model_dict)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_engine\u001b[39m(\n\u001b[0;32m    199\u001b[0m     mode: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m    200\u001b[0m     model: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m    201\u001b[0m     mode_model_dict: Dict[Tuple[OpenAIEmbeddingMode, \u001b[38;5;28mstr\u001b[39m], OpenAIEmbeddingModeModel],\n\u001b[0;32m    202\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m    203\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get engine.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 204\u001b[0m     key \u001b[38;5;241m=\u001b[39m (OpenAIEmbeddingMode(mode), \u001b[43mOpenAIEmbeddingModelType\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode_model_dict:\n\u001b[0;32m    206\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid mode, model combination: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\enum.py:714\u001b[0m, in \u001b[0;36mEnumType.__call__\u001b[1;34m(cls, value, names, module, qualname, type, start, boundary)\u001b[0m\n\u001b[0;32m    689\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    690\u001b[0m \u001b[38;5;124;03mEither returns an existing member, or creates a new enum class.\u001b[39;00m\n\u001b[0;32m    691\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    711\u001b[0m \u001b[38;5;124;03m`type`, if set, will be mixed in as the first base class.\u001b[39;00m\n\u001b[0;32m    712\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# simple value lookup\u001b[39;00m\n\u001b[1;32m--> 714\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__new__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    715\u001b[0m \u001b[38;5;66;03m# otherwise, functional API: we're creating a new Enum type\u001b[39;00m\n\u001b[0;32m    716\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_create_(\n\u001b[0;32m    717\u001b[0m         value,\n\u001b[0;32m    718\u001b[0m         names,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    723\u001b[0m         boundary\u001b[38;5;241m=\u001b[39mboundary,\n\u001b[0;32m    724\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\enum.py:1137\u001b[0m, in \u001b[0;36mEnum.__new__\u001b[1;34m(cls, value)\u001b[0m\n\u001b[0;32m   1135\u001b[0m ve_exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m is not a valid \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (value, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m))\n\u001b[0;32m   1136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ve_exc\n\u001b[0;32m   1138\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1139\u001b[0m     exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   1140\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror in \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m._missing_: returned \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m instead of None or a valid member\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1141\u001b[0m             \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, result)\n\u001b[0;32m   1142\u001b[0m             )\n",
      "\u001b[1;31mValueError\u001b[0m: 'mxbai-embed-large:latest' is not a valid OpenAIEmbeddingModelType"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import tinytroupe\n",
    "from tinytroupe.agent import TinyPerson\n",
    "from tinytroupe.environment import TinyWorld, TinySocialNetwork\n",
    "from tinytroupe.examples import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "world = TinyWorld(\"Focus group\", [create_lisa_the_data_scientist(), create_oscar_the_architect(), create_marcos_the_physician()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.broadcast(\"\"\"\n",
    "                Hello everyone! Let's start by introducing ourselves. What is your job and what are some major problems you face in your work? \n",
    "                What are major challenges for your industry as a whole? Don't discuss solutions yet, just the problems you face.\n",
    "                \"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.run(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.broadcast(\"\"\"\n",
    "                Folks, your mission is to brainstorm potential AI feature ideas\n",
    "                to add to Microsoft Word. In general, we want features that make you or your industry more productive,\n",
    "                taking advantage of all the latest AI technologies. Think about the problems you described - what could help with them? \n",
    "                Avoid obvious ideas, like summarization or translation. Also avoid simple things like minor UI improvements. \n",
    "                We want to think big here - you can fully reimagine Word if that's what it takes. \n",
    "                Do not worry about implementation details, marketing, or any other business considerations. \n",
    "                Just focus on the AI feature ideas themselves. Select and develop the most promising ideas.\n",
    "                    \n",
    "                Please start the discussion now.\n",
    "                \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.run(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.broadcast(\"\"\"\n",
    "                Ok, great. Now please add more details to these ideas - we need to understand them better. How would they actually integrate with Word? \n",
    "                Can you provide some concrete examples of what customers could do?\n",
    "                \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.run(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rapporteur = world.get_agent_by_name(\"Lisa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rapporteur.listen_and_act(\"Can you please consolidate the ideas that the group came up with? Provide a lot of details on each idea, and complement anything missing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinytroupe.extraction import ResultsExtractor\n",
    "\n",
    "extractor = ResultsExtractor()\n",
    "\n",
    "extractor.extract_results_from_agent(rapporteur, \n",
    "                          extraction_objective=\"Consolidates the ideas that the group came up with, explaining each idea as an item of a list.\" \\\n",
    "                                               \"Add all relevant details, including key benefits and drawbacks, if any.\", \n",
    "                          situation=\"A focus group to brainstorm AI feature ideas for Microsoft Word.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
